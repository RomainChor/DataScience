{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019915,
     "end_time": "2021-02-18T12:00:07.436967",
     "exception": false,
     "start_time": "2021-02-18T12:00:07.417052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training notebook using TPU for \"Cassava leaf disease classification\" competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:07.477075Z",
     "iopub.status.busy": "2021-02-18T12:00:07.476384Z",
     "iopub.status.idle": "2021-02-18T12:00:07.509432Z",
     "shell.execute_reply": "2021-02-18T12:00:07.508526Z"
    },
    "papermill": {
     "duration": 0.054281,
     "end_time": "2021-02-18T12:00:07.509674",
     "exception": false,
     "start_time": "2021-02-18T12:00:07.455393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:07.553470Z",
     "iopub.status.busy": "2021-02-18T12:00:07.552785Z",
     "iopub.status.idle": "2021-02-18T12:00:14.022080Z",
     "shell.execute_reply": "2021-02-18T12:00:14.021018Z"
    },
    "papermill": {
     "duration": 6.493485,
     "end_time": "2021-02-18T12:00:14.022304",
     "exception": false,
     "start_time": "2021-02-18T12:00:07.528819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:14.067335Z",
     "iopub.status.busy": "2021-02-18T12:00:14.066297Z",
     "iopub.status.idle": "2021-02-18T12:00:14.126117Z",
     "shell.execute_reply": "2021-02-18T12:00:14.125423Z"
    },
    "papermill": {
     "duration": 0.084548,
     "end_time": "2021-02-18T12:00:14.126289",
     "exception": false,
     "start_time": "2021-02-18T12:00:14.041741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BASE PATHS\n",
    "BASE_DIR = Path(\"../input/cassava-leaf-disease-classification\") #Path to data directory\n",
    "MODELS_DIR = Path(\"../input/training\") #Path to saved models\n",
    "IMAGE_DIR = Path(BASE_DIR, \"train_images\") #Path to images directory\n",
    "OUTPUT_DIR = Path(\"./\") #Path to 'output' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:14.169995Z",
     "iopub.status.busy": "2021-02-18T12:00:14.169015Z",
     "iopub.status.idle": "2021-02-18T12:00:14.240489Z",
     "shell.execute_reply": "2021-02-18T12:00:14.239666Z"
    },
    "papermill": {
     "duration": 0.095713,
     "end_time": "2021-02-18T12:00:14.240645",
     "exception": false,
     "start_time": "2021-02-18T12:00:14.144932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Cassava Bacterial Blight (CBB)',\n",
       " 1: 'Cassava Brown Streak Disease (CBSD)',\n",
       " 2: 'Cassava Green Mottle (CGM)',\n",
       " 3: 'Cassava Mosaic Disease (CMD)',\n",
       " 4: 'Healthy'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(Path(BASE_DIR, \"label_num_to_disease_map.json\"), 'r') as infile:\n",
    "    map_classes = json.load(infile)\n",
    "map_classes = {int(k):v for k, v in map_classes.items()}\n",
    "map_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:14.286587Z",
     "iopub.status.busy": "2021-02-18T12:00:14.285891Z",
     "iopub.status.idle": "2021-02-18T12:00:14.400722Z",
     "shell.execute_reply": "2021-02-18T12:00:14.399917Z"
    },
    "papermill": {
     "duration": 0.140592,
     "end_time": "2021-02-18T12:00:14.400949",
     "exception": false,
     "start_time": "2021-02-18T12:00:14.260357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(BASE_DIR, \"train.csv\"))\n",
    "data['class_name'] = data['label'].map(map_classes)\n",
    "freqs = 1 - np.unique(data[\"label\"], return_counts=True)[1]/data.shape[0]\n",
    "LOSS_WEIGHTS = {i:10*freqs[i] for i in range(5)} #Weights for loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:14.447875Z",
     "iopub.status.busy": "2021-02-18T12:00:14.446776Z",
     "iopub.status.idle": "2021-02-18T12:00:20.194838Z",
     "shell.execute_reply": "2021-02-18T12:00:20.195988Z"
    },
    "papermill": {
     "duration": 5.775316,
     "end_time": "2021-02-18T12:00:20.196285",
     "exception": false,
     "start_time": "2021-02-18T12:00:14.420969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: grpc://10.0.0.2:8470\n"
     ]
    }
   ],
   "source": [
    "# For TPU training\n",
    "TPU = tf.distribute.cluster_resolver.TPUClusterResolver.connect() #Detect and init the TPU\n",
    "print('Device:', TPU.master())\n",
    "TPU_STRATEGY = tf.distribute.experimental.TPUStrategy(TPU) #Instantiate a distribution strategy\n",
    "REPLICAS = TPU_STRATEGY.num_replicas_in_sync\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:20.243600Z",
     "iopub.status.busy": "2021-02-18T12:00:20.242887Z",
     "iopub.status.idle": "2021-02-18T12:00:20.304057Z",
     "shell.execute_reply": "2021-02-18T12:00:20.303476Z"
    },
    "papermill": {
     "duration": 0.088312,
     "end_time": "2021-02-18T12:00:20.304229",
     "exception": false,
     "start_time": "2021-02-18T12:00:20.215917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import Xception, InceptionV3, EfficientNetB0, EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_bfloat16')\n",
    "# mixed_precision.set_policy(policy) #shortens training time by 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:20.349961Z",
     "iopub.status.busy": "2021-02-18T12:00:20.349276Z",
     "iopub.status.idle": "2021-02-18T12:00:20.408300Z",
     "shell.execute_reply": "2021-02-18T12:00:20.407722Z"
    },
    "papermill": {
     "duration": 0.083403,
     "end_time": "2021-02-18T12:00:20.408451",
     "exception": false,
     "start_time": "2021-02-18T12:00:20.325048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "DEBUG = False\n",
    "SEED = 117\n",
    "IMAGE_SIZE = 512 #Parameter to choose wisely\n",
    "TARGET_SIZE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "N_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:20.453306Z",
     "iopub.status.busy": "2021-02-18T12:00:20.452616Z",
     "iopub.status.idle": "2021-02-18T12:00:21.209266Z",
     "shell.execute_reply": "2021-02-18T12:00:21.209835Z"
    },
    "papermill": {
     "duration": 0.782218,
     "end_time": "2021-02-18T12:00:21.210028",
     "exception": false,
     "start_time": "2021-02-18T12:00:20.427810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\n",
    "FILENAMES = tf.io.gfile.glob(GCS_PATH+'/train_tfrecords/*.tfrec')\n",
    "FILENAMES, TEST_FILENAMES = train_test_split(FILENAMES, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.263152Z",
     "iopub.status.busy": "2021-02-18T12:00:21.262063Z",
     "iopub.status.idle": "2021-02-18T12:00:21.341491Z",
     "shell.execute_reply": "2021-02-18T12:00:21.342031Z"
    },
    "papermill": {
     "duration": 0.109956,
     "end_time": "2021-02-18T12:00:21.342242",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.232286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets utility functions\n",
    "def one_hot(image, label):\n",
    "    label = tf.one_hot(label, N_CLASSES, dtype=tf.float32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def decode_image(image_data):\n",
    "    \"\"\"\n",
    "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
    "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
    "        3. Resize and reshape images to the expected size.\n",
    "    \"\"\"\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float64) #/255.0\n",
    "    image = PREPROCESS_FUNC(image)\n",
    "                      \n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    \n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled=True):\n",
    "    \"\"\"\n",
    "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
    "        2. Decode image.\n",
    "        3. If 'labeled' returns (image, label) if not (image, name).\n",
    "    \"\"\"\n",
    "    if labeled:\n",
    "        TFREC_FORMAT = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string), \n",
    "            'target': tf.io.FixedLenFeature([], tf.int64), \n",
    "        }\n",
    "    else:\n",
    "        TFREC_FORMAT = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string), \n",
    "            'image_name': tf.io.FixedLenFeature([], tf.string), \n",
    "        }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "    else:\n",
    "        label = example['image_name']\n",
    "        \n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    \"\"\"\n",
    "        Create a Tensorflow dataset from TFRecords.\n",
    "    \"\"\"\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset(filenames, labeled=True, ordered=False, repeated=False, augment=True, drop_remainder=False):\n",
    "    \"\"\"\n",
    "        Return a Tensorflow dataset ready for training or inference.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(filenames, labeled=labeled, ordered=ordered)\n",
    "    dataset = dataset.map(one_hot, num_parallel_calls=AUTO)\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if augment:\n",
    "        dataset = dataset.batch(AUG_BATCH)\n",
    "        dataset = dataset.map(transform, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.unbatch()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(SEED)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=drop_remainder)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.387734Z",
     "iopub.status.busy": "2021-02-18T12:00:21.386700Z",
     "iopub.status.idle": "2021-02-18T12:00:21.463268Z",
     "shell.execute_reply": "2021-02-18T12:00:21.463759Z"
    },
    "papermill": {
     "duration": 0.101853,
     "end_time": "2021-02-18T12:00:21.463948",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.362095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cutmix(image, label, prob=1.0):\n",
    "    \"\"\"\n",
    "        image: a batch of images of size [AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3]\n",
    "    \"\"\"\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast(tf.random.uniform([], 0, 1)<=prob, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast(tf.random.uniform([], 0, AUG_BATCH), tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast(tf.random.uniform([], 0, IMAGE_SIZE), tf.int32)\n",
    "        y = tf.cast(tf.random.uniform([], 0, IMAGE_SIZE), tf.int32)\n",
    "        b = tf.random.uniform([], 0, 1) # this is beta dist with alpha=1.0\n",
    "        width = tf.cast(IMAGE_SIZE*tf.math.sqrt(1-b), tf.int32)*P\n",
    "        ya = tf.math.maximum(0, y-width//2)\n",
    "        yb = tf.math.minimum(IMAGE_SIZE, y+width//2)\n",
    "        xa = tf.math.maximum(0, x-width//2)\n",
    "        xb = tf.math.minimum(IMAGE_SIZE, x+width//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j, ya:yb, 0:xa, :]\n",
    "        two = image[k, ya:yb, xa:xb, :]\n",
    "        three = image[j, ya:yb, xb:IMAGE_SIZE, :]\n",
    "        middle = tf.concat([one, two, three], axis=1)\n",
    "        img = tf.concat([image[j, 0:ya, :, :], middle, image[j, yb:IMAGE_SIZE, :, :]], axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(width*width/IMAGE_SIZE/IMAGE_SIZE, tf.float32)\n",
    "        if len(label.shape) == 1:\n",
    "            lab1 = tf.one_hot(label[j], N_CLASSES)\n",
    "            lab2 = tf.one_hot(label[k], N_CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j, ]\n",
    "            lab2 = label[k, ]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs), (AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    label2 = tf.reshape(tf.stack(labs), (AUG_BATCH, N_CLASSES))\n",
    "    \n",
    "    return image2, label2\n",
    "\n",
    "\n",
    "def mixup(image, label, prob=1.0):\n",
    "    \"\"\"\n",
    "        image: a batch of images of size [AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3]\n",
    "    \"\"\"\n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast(tf.random.uniform([], 0, 1)<=prob, tf.float32)\n",
    "        # CHOOSE RANDOM\n",
    "        k = tf.cast(tf.random.uniform([], 0, AUG_BATCH), tf.int32)\n",
    "        a = tf.random.uniform([], 0, 1)*P # this is beta dist with alpha=1.0\n",
    "        # MAKE MIXUP IMAGE\n",
    "        img1 = image[j, ]\n",
    "        img2 = image[k, ]\n",
    "        imgs.append((1-a)*img1 + a*img2)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        if len(label.shape) == 1:\n",
    "            lab1 = tf.one_hot(label[j], N_CLASSES)\n",
    "            lab2 = tf.one_hot(label[k], N_CLASSES)\n",
    "        else:\n",
    "            lab1 = label[j, ]\n",
    "            lab2 = label[k, ]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs), (AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE,3))\n",
    "    label2 = tf.reshape(tf.stack(labs), (AUG_BATCH, N_CLASSES))\n",
    "    \n",
    "    return image2, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.515488Z",
     "iopub.status.busy": "2021-02-18T12:00:21.514751Z",
     "iopub.status.idle": "2021-02-18T12:00:21.575596Z",
     "shell.execute_reply": "2021-02-18T12:00:21.576175Z"
    },
    "papermill": {
     "duration": 0.092452,
     "end_time": "2021-02-18T12:00:21.576382",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.483930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_flips(image):\n",
    "    img = tf.image.random_flip_left_right(image)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def transform(image, label):\n",
    "    \"\"\"\n",
    "        image: a batch of images of size [AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3]\n",
    "    \"\"\"\n",
    "    switch = 0.5\n",
    "    cutmix_prob = 0.666\n",
    "    mixup_prob = 0.666\n",
    "    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n",
    "    image1 = []\n",
    "    for j in range(AUG_BATCH):\n",
    "#         img = transform_mat(image[j, ])\n",
    "        img = image[j, ]\n",
    "        img = apply_flips(img)\n",
    "        image1.append(img)\n",
    "        \n",
    "    image1 = tf.reshape(tf.stack(image1), (AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    image2, label2 = cutmix(image1, label, cutmix_prob)\n",
    "    image3, label3 = mixup(image1, label, mixup_prob)\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        P = tf.cast(tf.random.uniform([], 0, 1)<=switch, tf.float32)\n",
    "        imgs.append(P*image2[j, ]+(1-P)*image3[j, ])\n",
    "        labs.append(P*label2[j, ]+(1-P)*label3[j ,])\n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image4 = tf.reshape(tf.stack(imgs), (AUG_BATCH, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    label4 = tf.reshape(tf.stack(labs), (AUG_BATCH, N_CLASSES))\n",
    "    \n",
    "    return image4, label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.623997Z",
     "iopub.status.busy": "2021-02-18T12:00:21.623311Z",
     "iopub.status.idle": "2021-02-18T12:00:21.684745Z",
     "shell.execute_reply": "2021-02-18T12:00:21.684035Z"
    },
    "papermill": {
     "duration": 0.08836,
     "end_time": "2021-02-18T12:00:21.684897",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.596537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing functions\n",
    "# def augment_train(image, label):\n",
    "#     p_flip_lr = np.random.uniform()\n",
    "#     p_flip_ud = np.random.uniform()\n",
    "#     if p_flip_lr >= 0.5:\n",
    "#         image = tf.image.random_flip_left_right(image)\n",
    "#     if p_flip_ud >= 0.5:\n",
    "#         image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "#     return image, label\n",
    "\n",
    "# def augment_test(image, label):\n",
    "#     return image, label\n",
    "\n",
    "def to_float32(image, label):\n",
    "    return tf.cast(image, tf.float32), label\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n",
    "    \n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.733509Z",
     "iopub.status.busy": "2021-02-18T12:00:21.732779Z",
     "iopub.status.idle": "2021-02-18T12:00:21.792772Z",
     "shell.execute_reply": "2021-02-18T12:00:21.792177Z"
    },
    "papermill": {
     "duration": 0.087592,
     "end_time": "2021-02-18T12:00:21.792930",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.705338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(model_name, num_classes=N_CLASSES, pretrained=True, freeze=False):\n",
    "    weights = None\n",
    "    trainable = True\n",
    "    if pretrained:\n",
    "        weights = \"imagenet\"\n",
    "        if freeze:\n",
    "            trainable = False\n",
    "        \n",
    "    base_model = getattr(tf.keras.applications, model_name)(include_top=False, \n",
    "                                                            weights=weights, \n",
    "                                                            input_shape=INPUT_SHAPE)\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    inputs = Input(shape=INPUT_SHAPE)\n",
    "    x = base_model(inputs) #'training=False' allows keeping batch norm layers in inference mode when unfreezing\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x, training=True)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\", dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.840828Z",
     "iopub.status.busy": "2021-02-18T12:00:21.840125Z",
     "iopub.status.idle": "2021-02-18T12:00:21.900735Z",
     "shell.execute_reply": "2021-02-18T12:00:21.899934Z"
    },
    "papermill": {
     "duration": 0.087518,
     "end_time": "2021-02-18T12:00:21.900901",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.813383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LR scheduler (rampup) HP\n",
    "LR_START = 1e-5\n",
    "LR_MAX = 5e-5*REPLICAS\n",
    "LR_MIN = 1e-5\n",
    "LR_RAMPUP_EPOCHS = 5\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_scheduler = LearningRateScheduler(lrfn, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:21.952990Z",
     "iopub.status.busy": "2021-02-18T12:00:21.952258Z",
     "iopub.status.idle": "2021-02-18T12:00:22.071804Z",
     "shell.execute_reply": "2021-02-18T12:00:22.072436Z"
    },
    "papermill": {
     "duration": 0.14987,
     "end_time": "2021-02-18T12:00:22.072629",
     "exception": false,
     "start_time": "2021-02-18T12:00:21.922759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.backend import set_value, get_value\n",
    "from keras import backend as Kk\n",
    "\n",
    "\n",
    "class CosineAnnealingScheduler(Callback):\n",
    "    \"\"\"\n",
    "        Cosine annealing scheduler.\n",
    "    \"\"\"\n",
    "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
    "        super(CosineAnnealingScheduler, self).__init__()\n",
    "        self.T_max = T_max\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + np.cos(np.pi * epoch / self.T_max)) / 2\n",
    "        set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
    "                  'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020715,
     "end_time": "2021-02-18T12:00:22.114620",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.093905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.159916Z",
     "iopub.status.busy": "2021-02-18T12:00:22.159251Z",
     "iopub.status.idle": "2021-02-18T12:00:22.218503Z",
     "shell.execute_reply": "2021-02-18T12:00:22.219068Z"
    },
    "papermill": {
     "duration": 0.08342,
     "end_time": "2021-02-18T12:00:22.219268",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.135848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64*REPLICAS #NUMBER IN FRONT OF REPLIAS CAN BE CHANGED (MAX. 128)\n",
    "# AUG_BATCH = BATCH_SIZE//2\n",
    "# STEPS_PER_EXECUTION = 16\n",
    "# # LR = 5e-5*REPLICAS #SHOULDN'T BE CHANGED\n",
    "# LR = 1e-3\n",
    "# EPOCHS = 20\n",
    "# PATIENCE = 5\n",
    "\n",
    "# PREPROCESS_FUNC = tf.keras.applications.xception.preprocess_input\n",
    "# TRAIN_FILENAMES, VAL_FILENAMES = train_test_split(FILENAMES, test_size=0.3, random_state=SEED)\n",
    "# train_dataset = get_dataset(TRAIN_FILENAMES, \n",
    "#                             labeled=True, \n",
    "#                             ordered=False, \n",
    "#                             repeated=True, \n",
    "#                             augment=True,\n",
    "#                             drop_remainder=False)\n",
    "# val_dataset = get_dataset(VAL_FILENAMES,\n",
    "#                          labeled=True, \n",
    "#                          ordered=True, \n",
    "#                          repeated=True, \n",
    "#                          augment=False, \n",
    "#                          drop_remainder=False)\n",
    "\n",
    "# STEPS_PER_EPOCH = count_data_items(TRAIN_FILENAMES)//BATCH_SIZE\n",
    "# VAL_STEPS = count_data_items(VAL_FILENAMES)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.264138Z",
     "iopub.status.busy": "2021-02-18T12:00:22.263495Z",
     "iopub.status.idle": "2021-02-18T12:00:22.323039Z",
     "shell.execute_reply": "2021-02-18T12:00:22.323621Z"
    },
    "papermill": {
     "duration": 0.083817,
     "end_time": "2021-02-18T12:00:22.323826",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.240009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if DEBUG: \n",
    "#     row = 6\n",
    "#     col = 4\n",
    "#     row = min(row, AUG_BATCH//col)\n",
    "#     all_elements = get_dataset(TRAIN_FILENAMES, \n",
    "#                                labeled=True, \n",
    "#                                ordered=False,\n",
    "#                                repeated=True,\n",
    "#                                augment=False).unbatch()\n",
    "#     aug_elements = all_elements.repeat().batch(AUG_BATCH).map(transform)\n",
    "\n",
    "#     for (img, label) in aug_elements:\n",
    "#         plt.figure(figsize=(15, int(15*row/col)))\n",
    "#         for j in range(row*col):\n",
    "#             plt.subplot(row, col, j+1)\n",
    "#             plt.axis('off')\n",
    "#             plt.imshow(img[j, ])\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.369345Z",
     "iopub.status.busy": "2021-02-18T12:00:22.368637Z",
     "iopub.status.idle": "2021-02-18T12:00:22.428065Z",
     "shell.execute_reply": "2021-02-18T12:00:22.428636Z"
    },
    "papermill": {
     "duration": 0.083748,
     "end_time": "2021-02-18T12:00:22.428828",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.345080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss = CategoricalCrossentropy(label_smoothing=0.2)\n",
    "# # loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "# optimizer = Adam(learning_rate=LR)\n",
    "\n",
    "\n",
    "# clear_session()\n",
    "# model_name = \"Xception\" #CHOOSE DESIRED MODEL\n",
    "# with TPU_STRATEGY.scope():\n",
    "#     model = build_model(model_name)\n",
    "#     model.compile(\n",
    "#         optimizer=optimizer,\n",
    "#         loss=loss,\n",
    "#         metrics=[\"accuracy\"],\n",
    "# #         steps_per_execution=STEPS_PER_EXECUTION\n",
    "#     )\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.474098Z",
     "iopub.status.busy": "2021-02-18T12:00:22.473467Z",
     "iopub.status.idle": "2021-02-18T12:00:22.534587Z",
     "shell.execute_reply": "2021-02-18T12:00:22.533944Z"
    },
    "papermill": {
     "duration": 0.084853,
     "end_time": "2021-02-18T12:00:22.534746",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.449893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     class_weight=LOSS_WEIGHTS,\n",
    "#     epochs=EPOCHS,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     validation_steps=VAL_STEPS,\n",
    "#     callbacks=[\n",
    "# #         CosineAnnealingScheduler(T_max=3, eta_min=1e-4, eta_max=1e-3, verbose=1),\n",
    "#         ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.3, min_delta=0.001),\n",
    "# #         lr_scheduler,\n",
    "#         EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1, min_delta=0.0001, restore_best_weights=True),\n",
    "#         ModelCheckpoint(filepath=Path(OUTPUT_DIR, model_name+\"_512.h5\"), monitor='val_loss', save_best_only=True)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.582122Z",
     "iopub.status.busy": "2021-02-18T12:00:22.581493Z",
     "iopub.status.idle": "2021-02-18T12:00:22.640839Z",
     "shell.execute_reply": "2021-02-18T12:00:22.640162Z"
    },
    "papermill": {
     "duration": 0.085037,
     "end_time": "2021-02-18T12:00:22.640997",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.555960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot(history.history['accuracy'])\n",
    "# ax[0].plot(history.history['val_accuracy'])\n",
    "# ax[0].set(xlabel=\"epoch\", ylabel=\"accuracy\", title=\"Model accuracy\")\n",
    "# ax[0].legend(['train', 'test'])\n",
    "\n",
    "# ax[1].plot(history.history['loss'])\n",
    "# ax[1].plot(history.history['val_loss'])\n",
    "# ax[1].set(xlabel=\"epoch\", ylabel=\"loss\", title=\"Model loss\")\n",
    "# ax[1].legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.688504Z",
     "iopub.status.busy": "2021-02-18T12:00:22.687805Z",
     "iopub.status.idle": "2021-02-18T12:00:22.746992Z",
     "shell.execute_reply": "2021-02-18T12:00:22.746178Z"
    },
    "papermill": {
     "duration": 0.084622,
     "end_time": "2021-02-18T12:00:22.747146",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.662524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataset = get_dataset(TEST_FILENAMES,\n",
    "#                            labeled=True,\n",
    "#                            ordered=True,\n",
    "#                            repeated=False,\n",
    "#                            augment=False,\n",
    "#                            drop_remainder=False)\n",
    "# test_images = test_dataset.map(lambda image, label: image)\n",
    "\n",
    "# STEPS = count_data_items(TEST_FILENAMES)//BATCH_SIZE\n",
    "# preds = model.predict(\n",
    "#     test_images,\n",
    "#     steps=STEPS,\n",
    "#     verbose=1\n",
    "# )\n",
    "# preds = np.argmax(preds, axis=1)\n",
    "# labels = np.argmax([target.numpy() for img, target in iter(test_dataset.unbatch())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.795301Z",
     "iopub.status.busy": "2021-02-18T12:00:22.794576Z",
     "iopub.status.idle": "2021-02-18T12:00:22.855182Z",
     "shell.execute_reply": "2021-02-18T12:00:22.854542Z"
    },
    "papermill": {
     "duration": 0.086398,
     "end_time": "2021-02-18T12:00:22.855354",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.768956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:22.904533Z",
     "iopub.status.busy": "2021-02-18T12:00:22.903817Z",
     "iopub.status.idle": "2021-02-18T12:00:22.963505Z",
     "shell.execute_reply": "2021-02-18T12:00:22.962764Z"
    },
    "papermill": {
     "duration": 0.085569,
     "end_time": "2021-02-18T12:00:22.963656",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.878087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from toolbox import plot_confusion_matrix\n",
    "\n",
    "# plot_confusion_matrix(preds, labels, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022787,
     "end_time": "2021-02-18T12:00:23.008869",
     "exception": false,
     "start_time": "2021-02-18T12:00:22.986082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:23.065455Z",
     "iopub.status.busy": "2021-02-18T12:00:23.064560Z",
     "iopub.status.idle": "2021-02-18T12:00:23.126371Z",
     "shell.execute_reply": "2021-02-18T12:00:23.125759Z"
    },
    "papermill": {
     "duration": 0.0955,
     "end_time": "2021-02-18T12:00:23.126517",
     "exception": false,
     "start_time": "2021-02-18T12:00:23.031017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_training(model_name, filenames, K=3):\n",
    "    i = 1\n",
    "    kf = KFold(n_splits=K)\n",
    "    filenames = np.array(filenames)\n",
    "    for train_index, val_index in kf.split(filenames):\n",
    "        print(\"Fold #\", i)\n",
    "        savepath = Path(OUTPUT_DIR, \"{0:s}_512_fold{1:d}.h5\".format(model_name, i))\n",
    "        \n",
    "        TRAIN_FILENAMES = filenames[train_index]\n",
    "        VAL_FILENAMES = filenames[val_index]\n",
    "        train_dataset = get_dataset(TRAIN_FILENAMES, \n",
    "                                    labeled=True, \n",
    "                                    ordered=False, \n",
    "                                    repeated=True, \n",
    "                                    augment=True,\n",
    "                                    drop_remainder=False)\n",
    "        val_dataset = get_dataset(VAL_FILENAMES,\n",
    "                                  labeled=True, \n",
    "                                  ordered=True, \n",
    "                                  repeated=True,\n",
    "                                  augment=False,\n",
    "                                  drop_remainder=False)\n",
    "        steps_per_epoch = count_data_items(TRAIN_FILENAMES)//BATCH_SIZE\n",
    "        val_steps = count_data_items(VAL_FILENAMES)//BATCH_SIZE\n",
    "\n",
    "        loss = CategoricalCrossentropy(label_smoothing=0.2)\n",
    "        optimizer = Adam(learning_rate=LR)\n",
    "        with TPU_STRATEGY.scope():\n",
    "            model = build_model(\n",
    "                model_name=model_name,\n",
    "                num_classes=5\n",
    "            )\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=[\"accuracy\"],\n",
    "#                 steps_per_execution=STEPS_PER_EXECUTION\n",
    "            )\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=val_steps,\n",
    "            class_weight=LOSS_WEIGHTS,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[\n",
    "                ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.3, min_delta=0.001),\n",
    "#                 lr_scheduler,\n",
    "                EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1, min_delta=0.0001, restore_best_weights=True),\n",
    "                ModelCheckpoint(filepath=savepath, monitor='val_loss', save_best_only=True)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:00:23.176001Z",
     "iopub.status.busy": "2021-02-18T12:00:23.175348Z",
     "iopub.status.idle": "2021-02-18T12:56:37.171637Z",
     "shell.execute_reply": "2021-02-18T12:56:37.172452Z"
    },
    "papermill": {
     "duration": 3374.024583,
     "end_time": "2021-02-18T12:56:37.172730",
     "exception": false,
     "start_time": "2021-02-18T12:00:23.148147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # 1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "Epoch 1/15\n",
      "23/23 [==============================] - 161s 3s/step - loss: 8.0801 - accuracy: 0.5928 - val_loss: 1.3495 - val_accuracy: 0.6991\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - 67s 3s/step - loss: 6.6510 - accuracy: 0.7829 - val_loss: 1.0646 - val_accuracy: 0.7823\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - 62s 3s/step - loss: 6.5157 - accuracy: 0.7972 - val_loss: 1.0970 - val_accuracy: 0.7580\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - 62s 3s/step - loss: 6.3337 - accuracy: 0.8166 - val_loss: 0.9820 - val_accuracy: 0.8268\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 6.0827 - accuracy: 0.8374 - val_loss: 0.9287 - val_accuracy: 0.8516\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 6.0718 - accuracy: 0.8405 - val_loss: 0.9286 - val_accuracy: 0.8565\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 5.8720 - accuracy: 0.8546 - val_loss: 0.9089 - val_accuracy: 0.8624\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 5.8484 - accuracy: 0.8593 - val_loss: 0.8938 - val_accuracy: 0.8667\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.8552 - accuracy: 0.8694 - val_loss: 0.8859 - val_accuracy: 0.8703\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - 63s 3s/step - loss: 5.7881 - accuracy: 0.8666 - val_loss: 0.8810 - val_accuracy: 0.8745\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - 58s 3s/step - loss: 5.9160 - accuracy: 0.8653 - val_loss: 0.8780 - val_accuracy: 0.8742\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - 61s 3s/step - loss: 5.8125 - accuracy: 0.8708 - val_loss: 0.8773 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.7604 - accuracy: 0.8772 - val_loss: 0.8767 - val_accuracy: 0.8741\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - 61s 3s/step - loss: 5.7132 - accuracy: 0.8837 - val_loss: 0.8748 - val_accuracy: 0.8730\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.7440 - accuracy: 0.8806 - val_loss: 0.8735 - val_accuracy: 0.8744\n",
      "Fold # 2\n",
      "Epoch 1/15\n",
      "23/23 [==============================] - 164s 3s/step - loss: 8.0076 - accuracy: 0.6109 - val_loss: 1.9681 - val_accuracy: 0.7175\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - 66s 3s/step - loss: 6.7455 - accuracy: 0.7733 - val_loss: 1.4046 - val_accuracy: 0.7486\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - 64s 3s/step - loss: 6.4755 - accuracy: 0.7937 - val_loss: 1.0901 - val_accuracy: 0.7894\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - 61s 3s/step - loss: 6.3401 - accuracy: 0.8020 - val_loss: 1.1207 - val_accuracy: 0.7921\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 6.2071 - accuracy: 0.8284 - val_loss: 1.0695 - val_accuracy: 0.8227\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.9748 - accuracy: 0.8455 - val_loss: 0.9770 - val_accuracy: 0.8489\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - 61s 3s/step - loss: 5.9396 - accuracy: 0.8599 - val_loss: 0.9114 - val_accuracy: 0.8610\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.9472 - accuracy: 0.8567 - val_loss: 0.9011 - val_accuracy: 0.8687\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.9008 - accuracy: 0.8620 - val_loss: 0.8859 - val_accuracy: 0.8667\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - 62s 3s/step - loss: 5.6935 - accuracy: 0.8700 - val_loss: 0.8912 - val_accuracy: 0.8684\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 5.6049 - accuracy: 0.8843 - val_loss: 0.8723 - val_accuracy: 0.8764\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 5.5793 - accuracy: 0.8853 - val_loss: 0.8738 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.5920 - accuracy: 0.8902 - val_loss: 0.8690 - val_accuracy: 0.8795\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - 59s 3s/step - loss: 5.4595 - accuracy: 0.8967 - val_loss: 0.8671 - val_accuracy: 0.8800\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - 60s 3s/step - loss: 5.6413 - accuracy: 0.8886 - val_loss: 0.8687 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Fold # 3\n",
      "Epoch 1/15\n",
      "26/26 [==============================] - 160s 3s/step - loss: 7.8165 - accuracy: 0.6501 - val_loss: 1.1806 - val_accuracy: 0.7590\n",
      "Epoch 2/15\n",
      "26/26 [==============================] - 70s 3s/step - loss: 6.7531 - accuracy: 0.7809 - val_loss: 1.0389 - val_accuracy: 0.7859\n",
      "Epoch 3/15\n",
      "26/26 [==============================] - 60s 2s/step - loss: 6.4366 - accuracy: 0.8036 - val_loss: 1.1395 - val_accuracy: 0.7563\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 4/15\n",
      "26/26 [==============================] - 60s 2s/step - loss: 6.2672 - accuracy: 0.8252 - val_loss: 0.9663 - val_accuracy: 0.8180\n",
      "Epoch 5/15\n",
      "26/26 [==============================] - 63s 2s/step - loss: 6.0425 - accuracy: 0.8396 - val_loss: 0.9365 - val_accuracy: 0.8318\n",
      "Epoch 6/15\n",
      "26/26 [==============================] - 59s 2s/step - loss: 6.1116 - accuracy: 0.8380 - val_loss: 0.9299 - val_accuracy: 0.8359\n",
      "Epoch 7/15\n",
      "26/26 [==============================] - 57s 2s/step - loss: 6.0294 - accuracy: 0.8474 - val_loss: 0.8834 - val_accuracy: 0.8732\n",
      "Epoch 8/15\n",
      "26/26 [==============================] - 61s 2s/step - loss: 5.9139 - accuracy: 0.8551 - val_loss: 0.8769 - val_accuracy: 0.8785\n",
      "Epoch 9/15\n",
      "26/26 [==============================] - 63s 2s/step - loss: 5.7823 - accuracy: 0.8677 - val_loss: 0.8944 - val_accuracy: 0.8754\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 10/15\n",
      "26/26 [==============================] - 64s 3s/step - loss: 5.8629 - accuracy: 0.8641 - val_loss: 0.8728 - val_accuracy: 0.8773\n",
      "Epoch 11/15\n",
      "26/26 [==============================] - 60s 2s/step - loss: 5.7126 - accuracy: 0.8712 - val_loss: 0.8691 - val_accuracy: 0.8840\n",
      "Epoch 12/15\n",
      "26/26 [==============================] - 63s 2s/step - loss: 5.6633 - accuracy: 0.8822 - val_loss: 0.8671 - val_accuracy: 0.8807\n",
      "Epoch 13/15\n",
      "26/26 [==============================] - 62s 2s/step - loss: 5.5503 - accuracy: 0.8879 - val_loss: 0.8700 - val_accuracy: 0.8789\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 14/15\n",
      "26/26 [==============================] - 60s 2s/step - loss: 5.5214 - accuracy: 0.8908 - val_loss: 0.8685 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 15/15\n",
      "26/26 [==============================] - 59s 2s/step - loss: 5.5865 - accuracy: 0.8871 - val_loss: 0.8662 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64*REPLICAS #NUMBER IN FRONT OF REPLIAS CAN BE CHANGED (MAX. 128)\n",
    "AUG_BATCH = BATCH_SIZE//2\n",
    "STEPS_PER_EXECUTION = 16\n",
    "# LR = 5e-5*REPLICAS #SHOULDN'T BE CHANGED\n",
    "LR = 1e-3\n",
    "EPOCHS = 15\n",
    "PATIENCE = 5\n",
    "\n",
    "PREPROCESS_FUNC = tf.keras.applications.xception.preprocess_input\n",
    "model = kfold_training(\"Xception\", FILENAMES, K=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3402.174703,
   "end_time": "2021-02-18T12:56:43.656307",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T12:00:01.481604",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
